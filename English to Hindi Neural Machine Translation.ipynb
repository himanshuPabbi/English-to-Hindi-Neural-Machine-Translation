{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc7b6980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f3d299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=pd.read_csv(\"Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91381868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>.The ending portion of these Vedas is called U...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127602</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>Examples of art deco construction can be found...</td>\n",
       "      <td>आर्ट डेको शैली के निर्माण मैरीन ड्राइव और ओवल ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127603</th>\n",
       "      <td>ted</td>\n",
       "      <td>and put it in our cheeks.</td>\n",
       "      <td>और अपने गालों में डाल लेते हैं।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127604</th>\n",
       "      <td>tides</td>\n",
       "      <td>As for the other derivatives of sulphur , the ...</td>\n",
       "      <td>जहां तक गंधक के अन्य उत्पादों का प्रश्न है , द...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127605</th>\n",
       "      <td>tides</td>\n",
       "      <td>its complicated functioning is defined thus in...</td>\n",
       "      <td>Zरचना-प्रकिया को उसने एक पहेली में यों बांधा है .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127606</th>\n",
       "      <td>ted</td>\n",
       "      <td>They've just won four government contracts to ...</td>\n",
       "      <td>हाल ही में उन्हें सरकारी ठेका मिला है करीब सौ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127607 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                   english_sentence  \\\n",
       "0             ted  politicians do not have permission to do what ...   \n",
       "1             ted         I'd like to tell you about one such child,   \n",
       "2       indic2012  This percentage is even greater than the perce...   \n",
       "3             ted  what we really mean is that they're bad at not...   \n",
       "4       indic2012  .The ending portion of these Vedas is called U...   \n",
       "...           ...                                                ...   \n",
       "127602  indic2012  Examples of art deco construction can be found...   \n",
       "127603        ted                          and put it in our cheeks.   \n",
       "127604      tides  As for the other derivatives of sulphur , the ...   \n",
       "127605      tides  its complicated functioning is defined thus in...   \n",
       "127606        ted  They've just won four government contracts to ...   \n",
       "\n",
       "                                           hindi_sentence  \n",
       "0       राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1       मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "2        यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "3          हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "4             इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  \n",
       "...                                                   ...  \n",
       "127602  आर्ट डेको शैली के निर्माण मैरीन ड्राइव और ओवल ...  \n",
       "127603                    और अपने गालों में डाल लेते हैं।  \n",
       "127604  जहां तक गंधक के अन्य उत्पादों का प्रश्न है , द...  \n",
       "127605  Zरचना-प्रकिया को उसने एक पहेली में यों बांधा है .  \n",
       "127606  हाल ही में उन्हें सरकारी ठेका मिला है करीब सौ ...  \n",
       "\n",
       "[127607 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6339b855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "tides        50000\n",
       "ted          39881\n",
       "indic2012    37726\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['source'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a294b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines[lines['source']=='ted']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaa482b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ted</td>\n",
       "      <td>And who are we to say, even, that they are wrong</td>\n",
       "      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ted</td>\n",
       "      <td>So there is some sort of justice</td>\n",
       "      <td>तो वहाँ न्याय है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ted</td>\n",
       "      <td>This changed slowly</td>\n",
       "      <td>धीरे धीरे ये सब बदला</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ted</td>\n",
       "      <td>were being produced.</td>\n",
       "      <td>उत्पन्न नहीं कि जाती थी.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ted</td>\n",
       "      <td>And you can see, this LED is going to glow.</td>\n",
       "      <td>और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ted</td>\n",
       "      <td>to turn on the lights or to bring him a glass ...</td>\n",
       "      <td>लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ted</td>\n",
       "      <td>Can you imagine saying that?</td>\n",
       "      <td>क्या आप ये कल्पना कर सकते है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ted</td>\n",
       "      <td>Three: this is a good road in - right near whe...</td>\n",
       "      <td>तीसरी: ये हमारी फ़ैक्ट्री के पास की एक अपेक्षा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ted</td>\n",
       "      <td>What's going on?”</td>\n",
       "      <td>क्या हो रहा है ये?”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ted</td>\n",
       "      <td>There are also financial reforms in rural China.</td>\n",
       "      <td>ग्रामीण चीन में आर्थिक नवीनीकरण हुये हैं।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ted</td>\n",
       "      <td>the family planning started in Vietnam and the...</td>\n",
       "      <td>वियतनाम में परिवार योजना शुरू हो गई और उनके पर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ted</td>\n",
       "      <td>I mean, at that time, trust me,</td>\n",
       "      <td>मेरा मतलब, उस समय, सही मानिए,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ted</td>\n",
       "      <td>Not only that,</td>\n",
       "      <td>बस वही नहीं,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ted</td>\n",
       "      <td>humans destroyed the commons that they depende...</td>\n",
       "      <td>मानवों ने उन ही साझे संसाधनों को नष्ट किया जिन...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ted</td>\n",
       "      <td>Almost goes to E, but otherwise the play would...</td>\n",
       "      <td>रचना करीब करीब ई तक जाती है, मगर तब तो नाटक ख़...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ted</td>\n",
       "      <td>So I want to share with you a couple key insights</td>\n",
       "      <td>मैं आपके साथ कुछ मुख्य सूत्र बाँटना चाहता हूँ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ted</td>\n",
       "      <td>Many countries in the [unclear], they need leg...</td>\n",
       "      <td>[अस्पष्ट] के बहुत सारे राष्ट्रों को मान्यता चा...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source                                   english_sentence  \\\n",
       "0     ted  politicians do not have permission to do what ...   \n",
       "1     ted         I'd like to tell you about one such child,   \n",
       "3     ted  what we really mean is that they're bad at not...   \n",
       "7     ted   And who are we to say, even, that they are wrong   \n",
       "13    ted                   So there is some sort of justice   \n",
       "23    ted                                This changed slowly   \n",
       "26    ted                               were being produced.   \n",
       "30    ted        And you can see, this LED is going to glow.   \n",
       "32    ted  to turn on the lights or to bring him a glass ...   \n",
       "35    ted                       Can you imagine saying that?   \n",
       "37    ted  Three: this is a good road in - right near whe...   \n",
       "39    ted                                  What's going on?”   \n",
       "42    ted   There are also financial reforms in rural China.   \n",
       "49    ted  the family planning started in Vietnam and the...   \n",
       "51    ted                    I mean, at that time, trust me,   \n",
       "53    ted                                     Not only that,   \n",
       "55    ted  humans destroyed the commons that they depende...   \n",
       "56    ted  Almost goes to E, but otherwise the play would...   \n",
       "63    ted  So I want to share with you a couple key insights   \n",
       "66    ted  Many countries in the [unclear], they need leg...   \n",
       "\n",
       "                                       hindi_sentence  \n",
       "0   राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1   मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "3      हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "7    और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं  \n",
       "13                                   तो वहाँ न्याय है  \n",
       "23                               धीरे धीरे ये सब बदला  \n",
       "26                           उत्पन्न नहीं कि जाती थी.  \n",
       "30       और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।  \n",
       "32    लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,  \n",
       "35                       क्या आप ये कल्पना कर सकते है  \n",
       "37  तीसरी: ये हमारी फ़ैक्ट्री के पास की एक अपेक्षा...  \n",
       "39                                क्या हो रहा है ये?”  \n",
       "42          ग्रामीण चीन में आर्थिक नवीनीकरण हुये हैं।  \n",
       "49  वियतनाम में परिवार योजना शुरू हो गई और उनके पर...  \n",
       "51                      मेरा मतलब, उस समय, सही मानिए,  \n",
       "53                                       बस वही नहीं,  \n",
       "55  मानवों ने उन ही साझे संसाधनों को नष्ट किया जिन...  \n",
       "56  रचना करीब करीब ई तक जाती है, मगर तब तो नाटक ख़...  \n",
       "63      मैं आपके साथ कुछ मुख्य सूत्र बाँटना चाहता हूँ  \n",
       "66  [अस्पष्ट] के बहुत सारे राष्ट्रों को मान्यता चा...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c99f33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source              0\n",
       "english_sentence    0\n",
       "hindi_sentence      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(lines).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2ca8fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines[~pd.isnull(lines['english_sentence'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50bd0697",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "459a658a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines=lines.sample(n=25000,random_state=42)\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68abfd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e4dc0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9711073",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4644557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "622dac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "708c3509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82040</th>\n",
       "      <td>ted</td>\n",
       "      <td>we still dont know who her parents are who she is</td>\n",
       "      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85038</th>\n",
       "      <td>ted</td>\n",
       "      <td>no keyboard</td>\n",
       "      <td>START_ कोई कुंजीपटल नहीं _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58018</th>\n",
       "      <td>ted</td>\n",
       "      <td>but as far as being a performer</td>\n",
       "      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74470</th>\n",
       "      <td>ted</td>\n",
       "      <td>and this particular balloon</td>\n",
       "      <td>START_ और यह खास गुब्बारा _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122330</th>\n",
       "      <td>ted</td>\n",
       "      <td>and its not as hard as you think integrate cli...</td>\n",
       "      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                   english_sentence  \\\n",
       "82040     ted  we still dont know who her parents are who she is   \n",
       "85038     ted                                        no keyboard   \n",
       "58018     ted                    but as far as being a performer   \n",
       "74470     ted                        and this particular balloon   \n",
       "122330    ted  and its not as hard as you think integrate cli...   \n",
       "\n",
       "                                           hindi_sentence  \n",
       "82040   START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...  \n",
       "85038                       START_ कोई कुंजीपटल नहीं _END  \n",
       "58018             START_ लेकिन एक कलाकार होने के साथ _END  \n",
       "74470                      START_ और यह खास गुब्बारा _END  \n",
       "122330  START_ और जितना आपको लगता है यह उतना कठिन नहीं...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8697bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in lines['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in lines['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d0ebd96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14030"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e6cfa05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17540"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hindi_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfe5184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffda1973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82040</th>\n",
       "      <td>ted</td>\n",
       "      <td>we still dont know who her parents are who she is</td>\n",
       "      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85038</th>\n",
       "      <td>ted</td>\n",
       "      <td>no keyboard</td>\n",
       "      <td>START_ कोई कुंजीपटल नहीं _END</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58018</th>\n",
       "      <td>ted</td>\n",
       "      <td>but as far as being a performer</td>\n",
       "      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74470</th>\n",
       "      <td>ted</td>\n",
       "      <td>and this particular balloon</td>\n",
       "      <td>START_ और यह खास गुब्बारा _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122330</th>\n",
       "      <td>ted</td>\n",
       "      <td>and its not as hard as you think integrate cli...</td>\n",
       "      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं...</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                   english_sentence  \\\n",
       "82040     ted  we still dont know who her parents are who she is   \n",
       "85038     ted                                        no keyboard   \n",
       "58018     ted                    but as far as being a performer   \n",
       "74470     ted                        and this particular balloon   \n",
       "122330    ted  and its not as hard as you think integrate cli...   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "82040   START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...   \n",
       "85038                       START_ कोई कुंजीपटल नहीं _END   \n",
       "58018             START_ लेकिन एक कलाकार होने के साथ _END   \n",
       "74470                      START_ और यह खास गुब्बारा _END   \n",
       "122330  START_ और जितना आपको लगता है यह उतना कठिन नहीं...   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "82040                    11                   16  \n",
       "85038                     2                    5  \n",
       "58018                     7                    8  \n",
       "74470                     4                    6  \n",
       "122330                   16                   20  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec475f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[lines['length_eng_sentence']>30].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7476de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines[lines['length_eng_sentence']<=20]\n",
    "lines=lines[lines['length_hin_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4641894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24774, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbd16f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  20\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8285db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_src=max(lines['length_hin_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab61e724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14030, 17540)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daab19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_decoder_tokens += 1 #for zero padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa0ffec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bee7eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "895ff787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13829</th>\n",
       "      <td>ted</td>\n",
       "      <td>and the way that we can solve problems</td>\n",
       "      <td>START_ और हमारे समस्या के समाधान ढूँढने के तरी...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112946</th>\n",
       "      <td>ted</td>\n",
       "      <td>we participate</td>\n",
       "      <td>START_ हम इसमें हिस्सा भी लेते हैं। _END</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69345</th>\n",
       "      <td>ted</td>\n",
       "      <td>and i framed it with color</td>\n",
       "      <td>START_ और मैंने उसे रंगीन फ्रेम दिया _END</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36015</th>\n",
       "      <td>ted</td>\n",
       "      <td>in the case of galileo he had two problems</td>\n",
       "      <td>START_ गैलीलियो के मामले में उनकी दो समस्या थी...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123205</th>\n",
       "      <td>ted</td>\n",
       "      <td>never visited the local art museum</td>\n",
       "      <td>START_ जो कभी स्थानीय कला संग्रहालय भी नहीं जा...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13003</th>\n",
       "      <td>ted</td>\n",
       "      <td>and it went from about million dollars to mill...</td>\n",
       "      <td>START_ और ये मिलियन से मिलियन तक बढ़ गया। _END</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31386</th>\n",
       "      <td>ted</td>\n",
       "      <td>okay so thats the warm up</td>\n",
       "      <td>START_ ठीक हैतो ये थी शुरूवाद _END</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72795</th>\n",
       "      <td>ted</td>\n",
       "      <td>the blue means no blood flow</td>\n",
       "      <td>START_ नीले का तात्पर्य है कि यहाँ खून नहीं जा...</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108389</th>\n",
       "      <td>ted</td>\n",
       "      <td>in the indian society</td>\n",
       "      <td>START_ भारतीय समाज में _END</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19169</th>\n",
       "      <td>ted</td>\n",
       "      <td>how do most of the women in the world wash</td>\n",
       "      <td>START_ दुनिया भर के ज्यादातर महिलाये कपड़े कैस...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                   english_sentence  \\\n",
       "13829     ted             and the way that we can solve problems   \n",
       "112946    ted                                     we participate   \n",
       "69345     ted                         and i framed it with color   \n",
       "36015     ted         in the case of galileo he had two problems   \n",
       "123205    ted                 never visited the local art museum   \n",
       "13003     ted  and it went from about million dollars to mill...   \n",
       "31386     ted                          okay so thats the warm up   \n",
       "72795     ted                       the blue means no blood flow   \n",
       "108389    ted                              in the indian society   \n",
       "19169     ted         how do most of the women in the world wash   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "13829   START_ और हमारे समस्या के समाधान ढूँढने के तरी...   \n",
       "112946           START_ हम इसमें हिस्सा भी लेते हैं। _END   \n",
       "69345           START_ और मैंने उसे रंगीन फ्रेम दिया _END   \n",
       "36015   START_ गैलीलियो के मामले में उनकी दो समस्या थी...   \n",
       "123205  START_ जो कभी स्थानीय कला संग्रहालय भी नहीं जा...   \n",
       "13003      START_ और ये मिलियन से मिलियन तक बढ़ गया। _END   \n",
       "31386                  START_ ठीक हैतो ये थी शुरूवाद _END   \n",
       "72795   START_ नीले का तात्पर्य है कि यहाँ खून नहीं जा...   \n",
       "108389                        START_ भारतीय समाज में _END   \n",
       "19169   START_ दुनिया भर के ज्यादातर महिलाये कपड़े कैस...   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "13829                     8                   11  \n",
       "112946                    2                    8  \n",
       "69345                     6                    8  \n",
       "36015                     9                   10  \n",
       "123205                    6                   11  \n",
       "13003                    10                   10  \n",
       "31386                     6                    7  \n",
       "72795                     6                   13  \n",
       "108389                    4                    5  \n",
       "19169                    10                   11  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa0c7aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19819,), (4955,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = lines['english_sentence'], lines['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddb83511",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ab29aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield((encoder_input_data, decoder_input_data), decoder_target_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a8221a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecbdaeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2dca3c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = dec]oder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24e35c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bce6518f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">     Param # </span>┃<span style=\"font-weight: bold\"> Connected to                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │   <span style=\"color: #00af00; text-decoration-color: #00af00\">4,209,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │   <span style=\"color: #00af00; text-decoration-color: #00af00\">5,262,300</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],               │\n",
       "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]        │             │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], │\n",
       "│                               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)] │             │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]                     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17541</span>)       │   <span style=\"color: #00af00; text-decoration-color: #00af00\">5,279,841</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                   │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────┴────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │           \u001b[38;5;34m0\u001b[0m │ -                              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │           \u001b[38;5;34m0\u001b[0m │ -                              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │   \u001b[38;5;34m4,209,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │           \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │   \u001b[38;5;34m5,262,300\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │     \u001b[38;5;34m721,200\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],               │\n",
       "│                               │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)]        │             │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                 │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),       │     \u001b[38;5;34m721,200\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], │\n",
       "│                               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)] │             │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]                     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17541\u001b[0m)       │   \u001b[38;5;34m5,279,841\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                   │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────┴────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,193,541</span> (61.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,193,541\u001b[0m (61.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,193,541</span> (61.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,193,541\u001b[0m (61.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bf1b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb2e41a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\himan\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for keras<2.16,>=2.15.0 from https://files.pythonhosted.org/packages/fc/a7/0d4490de967a67f68a538cc9cdb259bff971c4b5787f7765dc7c8f118f71/keras-2.15.0-py3-none-any.whl.metadata\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.26.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.0.4\n",
      "    Uninstalling keras-3.0.4:\n",
      "      Successfully uninstalled keras-3.0.4\n",
      "Successfully installed keras-2.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3e32ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\himan\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Collecting keras\n",
      "  Obtaining dependency information for keras from https://files.pythonhosted.org/packages/a3/31/982a0c8da5e06b8e915e09e7cae7f7815eecfef7e9e16fd733b105aa09ab/keras-3.0.4-py3-none-any.whl.metadata\n",
      "  Using cached keras-3.0.4-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\himan\\anaconda3\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\himan\\anaconda3\\lib\\site-packages (from keras) (1.24.3)\n",
      "Requirement already satisfied: rich in c:\\users\\himan\\anaconda3\\lib\\site-packages (from keras) (13.7.0)\n",
      "Requirement already satisfied: namex in c:\\users\\himan\\anaconda3\\lib\\site-packages (from keras) (0.0.7)\n",
      "Requirement already satisfied: h5py in c:\\users\\himan\\anaconda3\\lib\\site-packages (from keras) (3.9.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\himan\\anaconda3\\lib\\site-packages (from keras) (0.1.8)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\himan\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Using cached keras-3.0.4-py3-none-any.whl (1.0 MB)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.15.0\n",
      "    Uninstalling keras-2.15.0:\n",
      "      Successfully uninstalled keras-2.15.0\n",
      "Successfully installed keras-3.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e55867ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 3s/step - loss: 7.8717 - val_loss: 6.3495\n",
      "Epoch 2/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 3s/step - loss: 6.3139 - val_loss: 6.3078\n",
      "Epoch 3/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 3s/step - loss: 6.2592 - val_loss: 6.2723\n",
      "Epoch 4/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 3s/step - loss: 6.2009 - val_loss: 6.2013\n",
      "Epoch 5/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 910ms/step - loss: 6.1177 - val_loss: 6.1311\n",
      "Epoch 6/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 912ms/step - loss: 6.0429 - val_loss: 6.0577\n",
      "Epoch 7/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 906ms/step - loss: 5.9575 - val_loss: 5.9937\n",
      "Epoch 8/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 905ms/step - loss: 5.8840 - val_loss: 5.9374\n",
      "Epoch 9/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 899ms/step - loss: 5.8143 - val_loss: 5.8921\n",
      "Epoch 10/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 907ms/step - loss: 5.7474 - val_loss: 5.8403\n",
      "Epoch 11/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 904ms/step - loss: 5.6881 - val_loss: 5.8023\n",
      "Epoch 12/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 900ms/step - loss: 5.6349 - val_loss: 5.7647\n",
      "Epoch 13/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 935ms/step - loss: 5.5802 - val_loss: 5.7300\n",
      "Epoch 14/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 948ms/step - loss: 5.5272 - val_loss: 5.6981\n",
      "Epoch 15/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 909ms/step - loss: 5.4747 - val_loss: 5.6575\n",
      "Epoch 16/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 969ms/step - loss: 5.4187 - val_loss: 5.6311\n",
      "Epoch 17/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 987ms/step - loss: 5.3705 - val_loss: 5.6005\n",
      "Epoch 18/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 968ms/step - loss: 5.3289 - val_loss: 5.5770\n",
      "Epoch 19/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 3s/step - loss: 5.2816 - val_loss: 5.5484\n",
      "Epoch 20/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 952ms/step - loss: 5.2441 - val_loss: 5.5277\n",
      "Epoch 21/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 897ms/step - loss: 5.2029 - val_loss: 5.5033\n",
      "Epoch 22/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 917ms/step - loss: 5.1600 - val_loss: 5.4828\n",
      "Epoch 23/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 933ms/step - loss: 5.1164 - val_loss: 5.4610\n",
      "Epoch 24/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 961ms/step - loss: 5.0714 - val_loss: 5.4385\n",
      "Epoch 25/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 909ms/step - loss: 5.0312 - val_loss: 5.4177\n",
      "Epoch 26/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 904ms/step - loss: 4.9869 - val_loss: 5.4097\n",
      "Epoch 27/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 948ms/step - loss: 4.9460 - val_loss: 5.3891\n",
      "Epoch 28/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 924ms/step - loss: 4.9003 - val_loss: 5.3641\n",
      "Epoch 29/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 911ms/step - loss: 4.8586 - val_loss: 5.3491\n",
      "Epoch 30/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 918ms/step - loss: 4.8234 - val_loss: 5.3409\n",
      "Epoch 31/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 939ms/step - loss: 4.7880 - val_loss: 5.3413\n",
      "Epoch 32/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 938ms/step - loss: 4.7480 - val_loss: 5.3399\n",
      "Epoch 33/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 926ms/step - loss: 4.7131 - val_loss: 5.3320\n",
      "Epoch 34/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 925ms/step - loss: 4.6766 - val_loss: 5.3008\n",
      "Epoch 35/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 920ms/step - loss: 4.6398 - val_loss: 5.2867\n",
      "Epoch 36/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 945ms/step - loss: 4.6025 - val_loss: 5.2799\n",
      "Epoch 37/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 955ms/step - loss: 4.5672 - val_loss: 5.2718\n",
      "Epoch 38/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 952ms/step - loss: 4.5287 - val_loss: 5.2508\n",
      "Epoch 39/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 929ms/step - loss: 4.4963 - val_loss: 5.2498\n",
      "Epoch 40/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 943ms/step - loss: 4.4583 - val_loss: 5.2399\n",
      "Epoch 41/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 931ms/step - loss: 4.4224 - val_loss: 5.2425\n",
      "Epoch 42/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 959ms/step - loss: 4.3980 - val_loss: 5.2324\n",
      "Epoch 43/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40995s\u001b[0m 268s/step - loss: 4.3610 - val_loss: 5.2264\n",
      "Epoch 44/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 3s/step - loss: 4.3296 - val_loss: 5.2262\n",
      "Epoch 45/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 2s/step - loss: 4.2999 - val_loss: 5.2194\n",
      "Epoch 46/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 925ms/step - loss: 4.2648 - val_loss: 5.2130\n",
      "Epoch 47/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 927ms/step - loss: 4.2370 - val_loss: 5.2124\n",
      "Epoch 48/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 942ms/step - loss: 4.2077 - val_loss: 5.2167\n",
      "Epoch 49/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 919ms/step - loss: 4.1778 - val_loss: 5.2079\n",
      "Epoch 50/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 962ms/step - loss: 4.1425 - val_loss: 5.2101\n",
      "Epoch 51/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 918ms/step - loss: 4.1151 - val_loss: 5.2036\n",
      "Epoch 52/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 883ms/step - loss: 4.0817 - val_loss: 5.2130\n",
      "Epoch 53/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 897ms/step - loss: 4.0506 - val_loss: 5.2080\n",
      "Epoch 54/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 932ms/step - loss: 4.0179 - val_loss: 5.2244\n",
      "Epoch 55/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 894ms/step - loss: 3.9873 - val_loss: 5.2232\n",
      "Epoch 56/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 937ms/step - loss: 3.9554 - val_loss: 5.2169\n",
      "Epoch 57/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 912ms/step - loss: 3.9218 - val_loss: 5.2286\n",
      "Epoch 58/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 943ms/step - loss: 3.8920 - val_loss: 5.2370\n",
      "Epoch 59/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 944ms/step - loss: 3.8614 - val_loss: 5.2292\n",
      "Epoch 60/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 938ms/step - loss: 3.8322 - val_loss: 5.2294\n",
      "Epoch 61/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 910ms/step - loss: 3.8039 - val_loss: 5.2455\n",
      "Epoch 62/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 964ms/step - loss: 3.7745 - val_loss: 5.2506\n",
      "Epoch 63/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 940ms/step - loss: 3.7464 - val_loss: 5.2437\n",
      "Epoch 64/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 929ms/step - loss: 3.7116 - val_loss: 5.2447\n",
      "Epoch 65/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 925ms/step - loss: 3.6743 - val_loss: 5.2515\n",
      "Epoch 66/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 920ms/step - loss: 3.6473 - val_loss: 5.2681\n",
      "Epoch 67/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 925ms/step - loss: 3.6173 - val_loss: 5.2659\n",
      "Epoch 68/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 897ms/step - loss: 3.5879 - val_loss: 5.2665\n",
      "Epoch 69/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 944ms/step - loss: 3.5566 - val_loss: 5.2801\n",
      "Epoch 70/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 907ms/step - loss: 3.5276 - val_loss: 5.2837\n",
      "Epoch 71/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 894ms/step - loss: 3.4935 - val_loss: 5.2948\n",
      "Epoch 72/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 893ms/step - loss: 3.4687 - val_loss: 5.2932\n",
      "Epoch 73/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 895ms/step - loss: 3.4388 - val_loss: 5.3066\n",
      "Epoch 74/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 896ms/step - loss: 3.4036 - val_loss: 5.3188\n",
      "Epoch 75/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 904ms/step - loss: 3.3745 - val_loss: 5.3229\n",
      "Epoch 76/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 885ms/step - loss: 3.3467 - val_loss: 5.3366\n",
      "Epoch 77/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 936ms/step - loss: 3.3171 - val_loss: 5.3431\n",
      "Epoch 78/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 933ms/step - loss: 3.2844 - val_loss: 5.3482\n",
      "Epoch 79/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 990ms/step - loss: 3.2547 - val_loss: 5.3612\n",
      "Epoch 80/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 966ms/step - loss: 3.2226 - val_loss: 5.3765\n",
      "Epoch 81/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 934ms/step - loss: 3.1927 - val_loss: 5.3784\n",
      "Epoch 82/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 924ms/step - loss: 3.1610 - val_loss: 5.3803\n",
      "Epoch 83/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 917ms/step - loss: 3.1374 - val_loss: 5.4038\n",
      "Epoch 84/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 924ms/step - loss: 3.1063 - val_loss: 5.4073\n",
      "Epoch 85/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 934ms/step - loss: 3.0735 - val_loss: 5.4286\n",
      "Epoch 86/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 919ms/step - loss: 3.0441 - val_loss: 5.4261\n",
      "Epoch 87/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 938ms/step - loss: 3.0104 - val_loss: 5.4390\n",
      "Epoch 88/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 943ms/step - loss: 2.9784 - val_loss: 5.4635\n",
      "Epoch 89/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 3s/step - loss: 2.9486 - val_loss: 5.4791\n",
      "Epoch 90/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 3s/step - loss: 2.9176 - val_loss: 5.4923\n",
      "Epoch 91/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 3s/step - loss: 2.8886 - val_loss: 5.5041\n",
      "Epoch 92/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 3s/step - loss: 2.8473 - val_loss: 5.5214\n",
      "Epoch 93/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 3s/step - loss: 2.8236 - val_loss: 5.5295\n",
      "Epoch 94/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 3s/step - loss: 2.7917 - val_loss: 5.5345\n",
      "Epoch 95/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 2s/step - loss: 2.7634 - val_loss: 5.5483\n",
      "Epoch 96/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 1s/step - loss: 2.7310 - val_loss: 5.5739\n",
      "Epoch 97/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 1s/step - loss: 2.6984 - val_loss: 5.5990\n",
      "Epoch 98/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 2s/step - loss: 2.6683 - val_loss: 5.5901\n",
      "Epoch 99/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 1s/step - loss: 2.6392 - val_loss: 5.6013\n",
      "Epoch 100/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1s/step - loss: 2.6097 - val_loss: 5.6128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a3fa969cd0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=generate_batch(X_train, y_train, batch_size=batch_size),\n",
    "          steps_per_epoch=train_samples // batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=generate_batch(X_test, y_test, batch_size=batch_size),\n",
    "          validation_steps=val_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d26babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86b9be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99fec1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ada9af80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Input English sentence: than we ever would have thought\n",
      "Actual Hindi Translation:  हमारी आशा के मुकाबले। \n",
      "Predicted Hindi Translation:  हमें पता है कि हम बच्चों को खो देंगे \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31af7df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Input English sentence: was taking place\n",
      "Actual Hindi Translation:  चल रही थी। \n",
      "Predicted Hindi Translation:  वह खतरा था \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d27e20fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Input English sentence: and develop marketable products\n",
      "Actual Hindi Translation:  बाजार के लायक उत्पाद बनाये \n",
      "Predicted Hindi Translation:  बाजार के उपयोग से \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf31713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Input English sentence: we just did some pasting in los angeles\n",
      "Actual Hindi Translation:  हमने अभी लॉस एंजिलीस में तसवीरें चिपकायीं \n",
      "Predicted Hindi Translation:  हमने इसे दो बार में बार ले कर \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac78f943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Input English sentence: that education the process of education particularly higher education\n",
      "Actual Hindi Translation:  और पूरी शैक्षिक पद्धति खासकर उच्च शिक्षा की \n",
      "Predicted Hindi Translation:  तो ऊर्जा का एक बड़ा लिपि है \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c5b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
